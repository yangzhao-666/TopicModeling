{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ddm1924/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"SDDM\")\n",
    "# get the number of executers and cores\n",
    "# print(sc._jsc.sc().getExecutorMemoryStatus())\n",
    "# submit Sparkjobs\n",
    "# ./bin/spark-submit --driver-memory 4g --executor-memory 2G --master spark://fs.das3.liacs.nl:7077 sample_pyspark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIXZKN4ACSKI</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>David Briner</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This came in on time and I am veru happy with ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Woks very good</td>\n",
       "      <td>1390694400</td>\n",
       "      <td>01 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1L5P841VIO02V</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Jason A. Kramer</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>I had a factory Glock tool that I was using fo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Works as well as the factory tool</td>\n",
       "      <td>1328140800</td>\n",
       "      <td>02 2, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB2W04NI4OEAD</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>J. Fernald</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>If you don't have a 3/32 punch or would like t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It's a punch, that's all.</td>\n",
       "      <td>1330387200</td>\n",
       "      <td>02 28, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A148SVSWKTJKU6</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Jusitn A. Watts \"Maverick9614\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This works no better than any 3/32 punch you w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It's a punch with a Glock logo.</td>\n",
       "      <td>1328400000</td>\n",
       "      <td>02 5, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAWJ6LW9WMOO</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Material Man</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I purchased this thinking maybe I need a speci...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Ok,tool does what a regular punch does.</td>\n",
       "      <td>1366675200</td>\n",
       "      <td>04 23, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                    reviewerName helpful  \\\n",
       "0    AIXZKN4ACSKI  1881509818                    David Briner  [0, 0]   \n",
       "1  A1L5P841VIO02V  1881509818                 Jason A. Kramer  [1, 1]   \n",
       "2   AB2W04NI4OEAD  1881509818                      J. Fernald  [2, 2]   \n",
       "3  A148SVSWKTJKU6  1881509818  Jusitn A. Watts \"Maverick9614\"  [0, 0]   \n",
       "4   AAAWJ6LW9WMOO  1881509818                    Material Man  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This came in on time and I am veru happy with ...      5.0   \n",
       "1  I had a factory Glock tool that I was using fo...      5.0   \n",
       "2  If you don't have a 3/32 punch or would like t...      4.0   \n",
       "3  This works no better than any 3/32 punch you w...      4.0   \n",
       "4  I purchased this thinking maybe I need a speci...      4.0   \n",
       "\n",
       "                                   summary  unixReviewTime   reviewTime  \n",
       "0                           Woks very good      1390694400  01 26, 2014  \n",
       "1        Works as well as the factory tool      1328140800   02 2, 2012  \n",
       "2                It's a punch, that's all.      1330387200  02 28, 2012  \n",
       "3          It's a punch with a Glock logo.      1328400000   02 5, 2012  \n",
       "4  Ok,tool does what a regular punch does.      1366675200  04 23, 2013  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield (eval(l))\n",
    "        \n",
    "def GetDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient = \"index\")\n",
    "\n",
    "df = GetDF(\"reviews_Sports_and_Outdoors_5.json.gz\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['reviewText', 'summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df = SQLContext(sc).createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df = sp_df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          reviewText|             summary|\n",
      "+--------------------+--------------------+\n",
      "|This came in on t...|      Woks very good|\n",
      "|I had a factory G...|Works as well as ...|\n",
      "|If you don't have...|It's a punch, tha...|\n",
      "|This works no bet...|It's a punch with...|\n",
      "|I purchased this ...|Ok,tool does what...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sp_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(reviewText='This came in on time and I am veru happy with it, I haved used it already and it makes taking out the pins in my glock 32 very easy')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_df.select('reviewText').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sp_df.select('reviewText').rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "nltk_stpwd = stopwords.words(\"english\")\n",
    "stop_words_stpwd = get_stop_words('en')\n",
    "merged_stopwords = list(set(nltk_stpwd + stop_words_stpwd))\n",
    "sb_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropStopWords(s):\n",
    "    tokens = tokenizer.tokenize(s[0])\n",
    "    stopped_tokens = [token for token in tokens if token not in merged_stopwords]\n",
    "    stemmed_tokens = [sb_stemmer.stem(token) for token in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    return(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_rdd = rdd.flatMap(dropStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse the data\n",
    "data = sc.textFile(\"/home/ddm1924/spark/data/mllib/sample_lda_data.txt\")\n",
    "parsedData = data.map(lambda line: Vectors.dense([float(x) for x in line.strip().split(' ')]))\n",
    "# Index documents with unique IDs\n",
    "corpus = parsedData.zipWithIndex().map(lambda x: [x[1], x[0]]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([1.0, 2.0, 6.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 3.0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsedData.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned topics (as distributions over vocab of 11 words):\n",
      "Topic 0:\n",
      " 8.605904408398544\n",
      " 12.909497901537755\n",
      " 4.972791291787081\n",
      " 4.812989170255772\n",
      " 16.231428936190717\n",
      " 6.296126604096916\n",
      " 5.4738409512965385\n",
      " 4.407080087161346\n",
      " 3.3859620662775245\n",
      " 11.71424428022948\n",
      " 6.58118415293947\n",
      "Topic 1:\n",
      " 4.969888599351531\n",
      " 3.234325908093829\n",
      " 1.423420528714697\n",
      " 32.29408913417656\n",
      " 3.398065965889449\n",
      " 3.267226102097135\n",
      " 9.421411557650572\n",
      " 1.005248294078012\n",
      " 2.239044621393636\n",
      " 5.225087874983252\n",
      " 22.043814686429393\n",
      "Topic 2:\n",
      " 12.424206992249927\n",
      " 12.856176190368418\n",
      " 5.603788179498222\n",
      " 2.8929216955676678\n",
      " 5.370505097919837\n",
      " 12.43664729380595\n",
      " 16.10474749105289\n",
      " 4.587671618760642\n",
      " 2.374993312328839\n",
      " 7.06066784478727\n",
      " 4.375001160631137\n"
     ]
    }
   ],
   "source": [
    "# Cluster the documents into three topics using LDA\n",
    "ldaModel = LDA.train(corpus, k=3)\n",
    "\n",
    "# Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize())+ \" words):\")\n",
    "topics = ldaModel.topicsMatrix()\n",
    "for topic in range(3):\n",
    "    print(\"Topic \" + str(topic) + \":\")\n",
    "    for word in range(0, ldaModel.vocabSize()):\n",
    "        print(\" \" + str(topics[word][topic]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load model\n",
    "ldaModel.save(sc, \"target/org/apache/spark/PythonLatentDirichletAllocationExample/LDAModel\")\n",
    "sameModel = LDAModel.load(sc, \"target/org/apache/spark/PythonLatentDirichletAllocationExample/LDAModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([4, 1, 9, 0, 10, 5, 6, 2, 3, 7, 8],\n",
       "  [0.1900834919428993,\n",
       "   0.15118092498205635,\n",
       "   0.1371835139722902,\n",
       "   0.10078227663787527,\n",
       "   0.07707112354850948,\n",
       "   0.07373286328185714,\n",
       "   0.06410321644834033,\n",
       "   0.05823550946513061,\n",
       "   0.056364094114087375,\n",
       "   0.05161056217125915,\n",
       "   0.039652423435694986]),\n",
       " ([3, 10, 6, 9, 0, 4, 5, 1, 8, 2, 7],\n",
       "  [0.36481582623754666,\n",
       "   0.24902180813473992,\n",
       "   0.10643062349421809,\n",
       "   0.05902611906333325,\n",
       "   0.056143215811038635,\n",
       "   0.03838684651562803,\n",
       "   0.03690879111001245,\n",
       "   0.03653712831411121,\n",
       "   0.02529375918121191,\n",
       "   0.0160799189631573,\n",
       "   0.011355963175002403]),\n",
       " ([6, 1, 5, 0, 9, 2, 4, 7, 10, 3, 8],\n",
       "  [0.18707454482897956,\n",
       "   0.14933877792188216,\n",
       "   0.14446548342219317,\n",
       "   0.1443209754904531,\n",
       "   0.08201750595506141,\n",
       "   0.06509422911349906,\n",
       "   0.06238438679359784,\n",
       "   0.05329090570226417,\n",
       "   0.05082050191758821,\n",
       "   0.03360450138847967,\n",
       "   0.027588187466001727])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaModel.describeTopics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
